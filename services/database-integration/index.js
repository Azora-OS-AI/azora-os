/**
 * Azora OS - Comprehensive Database & Analytics Integration Service
 *
 * Enterprise-grade database integration with PostgreSQL, MongoDB, and Redis
 * providing real-time data sync, advanced analytics, and intelligent caching.
 *
 * Features:
 * - PostgreSQL with Prisma ORM (relational data, transactions, structured schemas)
 * - MongoDB for document storage (logs, analytics, flexible schemas)
 * - Redis for caching, sessions, real-time data, and pub/sub
 * - Real-time data synchronization
 * - Advanced analytics and reporting
 * - Intelligent caching strategies
 * - Data migration and backup
 * - Performance monitoring
 * - Automated data archiving
 */

// @ts-check
/**
 * @fileoverview Set sourceType: module for ES imports
 */
import express from 'express';
import { PrismaClient } from '@prisma/client';
import { MongoClient } from 'mongodb';
import Redis from 'redis';
import cors from 'cors';
import { createRequire } from 'module';
const require = createRequire(import.meta.url);

// Load environment variables
require('dotenv').config();

const app = express();
const PORT = process.env.DATABASE_PORT || 5002;

// ============================================================================
// DATABASE CONFIGURATION
// ============================================================================

const DB_CONFIG = {
  postgresql: {
    url: process.env.DATABASE_URL,
    schema: 'public'
  },
  mongodb: {
    uri: process.env.MONGO_URI,
    database: 'azora_os'
  },
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: process.env.REDIS_PORT || 6379,
    password: process.env.REDIS_PASSWORD,
    db: process.env.REDIS_DB || 0
  }
};

// ============================================================================
// DATABASE CONNECTIONS
// ============================================================================

class DatabaseManager {
  constructor() {
    this.prisma = null;
    this.mongoClient = null;
    this.redisClient = null;
    this.connections = {
      postgresql: false,
      mongodb: false,
      redis: false
    };
  }

  async connectPostgreSQL() {
    try {
      if (!process.env.DATABASE_URL) {
        console.log('‚ö†Ô∏è  PostgreSQL DATABASE_URL not configured, skipping connection');
        this.connections.postgresql = false;
        return;
      }

      this.prisma = new PrismaClient({
        datasourceUrl: DB_CONFIG.postgresql.url
      });

      await this.prisma.$connect();
      this.connections.postgresql = true;
      console.log('‚úÖ PostgreSQL connected via Prisma');
    } catch (error) {
      console.error('‚ùå PostgreSQL connection failed:', error.message);
      this.connections.postgresql = false;
      // Don't throw error, allow service to continue
    }
  }

  async connectMongoDB() {
    try {
      if (!process.env.MONGO_URI) {
        console.log('‚ö†Ô∏è  MongoDB MONGO_URI not configured, skipping connection');
        this.connections.mongodb = false;
        return;
      }

      this.mongoClient = new MongoClient(DB_CONFIG.mongodb.uri);
      await this.mongoClient.connect();
      this.mongoDb = this.mongoClient.db(DB_CONFIG.mongodb.database);
      this.connections.mongodb = true;
      console.log('‚úÖ MongoDB connected');
    } catch (error) {
      console.error('‚ùå MongoDB connection failed:', error.message);
      this.connections.mongodb = false;
      // Don't throw error, allow service to continue
    }
  }

  async connectRedis() {
    try {
      if (!process.env.REDIS_URL) {
        console.log('‚ö†Ô∏è  Redis REDIS_URL not configured, skipping connection');
        this.connections.redis = false;
        return;
      }

      // Use modern Redis client API
      this.redisClient = Redis.createClient({ url: process.env.REDIS_URL });

      this.redisClient.on('error', (err) => {
        console.error('Redis Client Error:', err);
        this.connections.redis = false;
      });

      this.redisClient.on('connect', () => {
        console.log('‚úÖ Redis connected');
        this.connections.redis = true;
      });

      await this.redisClient.connect();
    } catch (error) {
      console.error('‚ùå Redis connection failed:', error.message);
      this.connections.redis = false;
      // Don't throw error, allow service to continue
    }
  }

  async connectAll() {
    await Promise.allSettled([
      this.connectPostgreSQL(),
      this.connectMongoDB(),
      this.connectRedis()
    ]);

    const connectedCount = Object.values(this.connections).filter(Boolean).length;
    console.log(`üîó Database connections: ${connectedCount}/3 active`);
  }

  async disconnectAll() {
    try {
      if (this.prisma) await this.prisma.$disconnect();
      if (this.mongoClient) await this.mongoClient.close();
      if (this.redisClient && this.redisClient.isOpen) await this.redisClient.quit();
      console.log('üîå All database connections closed');
    } catch (error) {
      console.error('Error disconnecting databases:', error);
    }
  }

  getConnectionStatus() {
    return {
      postgresql: this.connections.postgresql,
      mongodb: this.connections.mongodb,
      redis: this.connections.redis,
      overall: Object.values(this.connections).every(Boolean)
    };
  }
}

// ============================================================================
// ANALYTICS ENGINE
// ============================================================================

class AnalyticsEngine {
  constructor(dbManager) {
    this.dbManager = dbManager;
    this.metrics = new Map();
    this.cache = new Map();
  }

  // Real-time metrics calculation
  async calculateMetrics(companyId, timeframe = '30d') {
    const cacheKey = `metrics:${companyId}:${timeframe}`;

    // Check cache first
    if (this.cache.has(cacheKey)) {
      const cached = this.cache.get(cacheKey);
      if (Date.now() - cached.timestamp < 300000) { // 5 minutes
        return cached.data;
      }
    }

    try {
      const metrics = await this.computeMetrics(companyId, timeframe);

      // Cache results
      this.cache.set(cacheKey, {
        data: metrics,
        timestamp: Date.now()
      });

      // Store in MongoDB for historical analysis
      await this.storeMetricsHistory(companyId, metrics, timeframe);

      return metrics;
    } catch (error) {
      console.error('Metrics calculation error:', error);
      throw error;
    }
  }

  async computeMetrics(companyId, timeframe) {
    const now = new Date();
    const startDate = new Date(now.getTime() - this.parseTimeframe(timeframe));

    // Revenue metrics
    const revenue = await this.dbManager.prisma.revenueRecord.aggregate({
      where: {
        companyId,
        recordDate: { gte: startDate }
      },
      _sum: { amount: true },
      _count: true
    });

    // Expense metrics
    const expenses = await this.dbManager.prisma.expense.aggregate({
      where: {
        companyId,
        expenseDate: { gte: startDate }
      },
      _sum: { amount: true },
      _count: true
    });

    // Operational metrics
    const jobs = await this.dbManager.prisma.job.findMany({
      where: {
        companyId,
        createdAt: { gte: startDate }
      },
      select: {
        status: true,
        createdAt: true
      }
    });

    const trips = await this.dbManager.prisma.trip.findMany({
      where: {
        vehicle: { companyId },
        createdAt: { gte: startDate }
      },
      select: {
        status: true,
        distance: true,
        incidents: true,
        riskScore: true
      }
    });

    // Safety metrics
    const incidents = await this.dbManager.prisma.safetyIncident.findMany({
      where: {
        companyId,
        reportedAt: { gte: startDate }
      },
      select: {
        severity: true,
        incidentType: true
      }
    });

    // HR metrics
    const employees = await this.dbManager.prisma.employee.count({
      where: { companyId, status: 'active' }
    });

    const leaveRequests = await this.dbManager.prisma.leaveRequest.count({
      where: {
        employee: { companyId },
        createdAt: { gte: startDate }
      }
    });

    // Calculate derived metrics
    const jobCompletionRate = jobs.length > 0 ?
      (jobs.filter(j => j.status === 'completed').length / jobs.length) * 100 : 0;

    const averageTripRisk = trips.length > 0 ?
      trips.reduce((sum, t) => sum + t.riskScore, 0) / trips.length : 0;

    const safetyIncidents = incidents.length;
    const criticalIncidents = incidents.filter(i => i.severity === 'critical').length;

    return {
      timeframe,
      period: { start: startDate.toISOString(), end: now.toISOString() },
      financial: {
        totalRevenue: revenue._sum.amount || 0,
        totalExpenses: expenses._sum.amount || 0,
        netProfit: (revenue._sum.amount || 0) - (expenses._sum.amount || 0),
        revenueTransactions: revenue._count,
        expenseTransactions: expenses._count
      },
      operational: {
        totalJobs: jobs.length,
        completedJobs: jobs.filter(j => j.status === 'completed').length,
        jobCompletionRate: Math.round(jobCompletionRate * 100) / 100,
        totalTrips: trips.length,
        totalDistance: trips.reduce((sum, t) => sum + t.distance, 0),
        averageTripRisk: Math.round(averageTripRisk * 100) / 100
      },
      safety: {
        totalIncidents: safetyIncidents,
        criticalIncidents,
        incidentRate: employees > 0 ? Math.round((safetyIncidents / employees) * 100) / 100 : 0
      },
      hr: {
        activeEmployees: employees,
        leaveRequests,
        leaveRate: employees > 0 ? Math.round((leaveRequests / employees) * 100) / 100 : 0
      },
      calculatedAt: now.toISOString()
    };
  }

  async storeMetricsHistory(companyId, metrics, timeframe) {
    if (!this.dbManager.mongoDb) return;

    const collection = this.dbManager.mongoDb.collection('metrics_history');

    await collection.insertOne({
      companyId,
      timeframe,
      metrics,
      createdAt: new Date()
    });

    // Keep only last 1000 records per company
    const count = await collection.countDocuments({ companyId });
    if (count > 1000) {
      const oldest = await collection.find({ companyId })
        .sort({ createdAt: 1 })
        .limit(count - 1000)
        .toArray();

      await collection.deleteMany({
        _id: { $in: oldest.map(doc => doc._id) }
      });
    }
  }

  parseTimeframe(timeframe) {
    const unit = timeframe.slice(-1);
    const value = parseInt(timeframe.slice(0, -1));

    const multipliers = {
      'h': 60 * 60 * 1000,
      'd': 24 * 60 * 60 * 1000,
      'w': 7 * 24 * 60 * 60 * 1000,
      'm': 30 * 24 * 60 * 60 * 1000,
      'y': 365 * 24 * 60 * 60 * 1000
    };

    return value * (multipliers[unit] || multipliers['d']);
  }

  // Predictive analytics
  async generatePredictions(companyId, metricType) {
    if (!this.dbManager.mongoDb) return null;

    const collection = this.dbManager.mongoDb.collection('metrics_history');

    // Get historical data for the last 90 days
    const ninetyDaysAgo = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);

    const historicalData = await collection.find({
      companyId,
      'metrics.calculatedAt': { $gte: ninetyDaysAgo.toISOString() }
    }).sort({ 'metrics.calculatedAt': 1 }).toArray();

    if (historicalData.length < 7) {
      return { error: 'Insufficient historical data for prediction' };
    }

    // Simple linear regression for prediction
    const predictions = this.predictTrend(historicalData, metricType);

    return {
      metricType,
      predictions,
      confidence: this.calculateConfidence(historicalData, metricType),
      basedOn: historicalData.length,
      nextUpdate: new Date(Date.now() + 24 * 60 * 60 * 1000).toISOString()
    };
  }

  predictTrend(data, metricType) {
    const values = data.map(d => this.extractMetricValue(d.metrics, metricType)).filter(v => v !== null);
    if (values.length < 2) return null;

    // Simple linear regression
    const n = values.length;
    const sumX = (n * (n - 1)) / 2;
    const sumY = values.reduce((sum, val) => sum + val, 0);
    const sumXY = values.reduce((sum, val, idx) => sum + val * idx, 0);
    const sumXX = (n * (n - 1) * (2 * n - 1)) / 6;

    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
    const intercept = (sumY - slope * sumX) / n;

    // Predict next 7 days
    const predictions = [];
    for (let i = 1; i <= 7; i++) {
      const predictedValue = slope * (n + i - 1) + intercept;
      predictions.push({
        day: i,
        predicted: Math.max(0, Math.round(predictedValue * 100) / 100),
        date: new Date(Date.now() + i * 24 * 60 * 60 * 1000).toISOString().split('T')[0]
      });
    }

    return predictions;
  }

  extractMetricValue(metrics, metricType) {
    const path = metricType.split('.');
    let value = metrics;

    for (const key of path) {
      value = value?.[key];
    }

    return typeof value === 'number' ? value : null;
  }

  calculateConfidence(data, metricType) {
    const values = data.map(d => this.extractMetricValue(d.metrics, metricType)).filter(v => v !== null);
    if (values.length < 2) return 0;

    // Calculate coefficient of variation as confidence measure
    const mean = values.reduce((sum, val) => sum + val, 0) / values.length;
    const variance = values.reduce((sum, val) => sum + Math.pow(val - mean, 2), 0) / values.length;
    const stdDev = Math.sqrt(variance);

    const cv = mean !== 0 ? stdDev / mean : 0;
    return Math.max(0, Math.min(1, 1 - cv)); // Higher confidence with lower variation
  }
}

// ============================================================================
// CACHING ENGINE
// ============================================================================

class CacheEngine {
  constructor(dbManager) {
    this.dbManager = dbManager;
    this.cacheStrategies = {
      'user': { ttl: 3600, maxSize: 1000 },      // 1 hour
      'metrics': { ttl: 300, maxSize: 500 },    // 5 minutes
      'analytics': { ttl: 600, maxSize: 200 },  // 10 minutes
      'session': { ttl: 1800, maxSize: 5000 }   // 30 minutes
    };
  }

  async get(key, strategy = 'default') {
    try {
      if (this.dbManager.redisClient) {
        const cached = await this.dbManager.redisClient.get(key);
        if (cached) {
          const parsed = JSON.parse(cached);
          if (this.isExpired(parsed)) {
            await this.delete(key);
            return null;
          }
          return parsed.data;
        }
      }
      return null;
    } catch (error) {
      console.error('Cache get error:', error);
      return null;
    }
  }

  async set(key, data, _strategy = 'default') {
    try {
      const config = (this.cacheStrategies as any)[_strategy] || { ttl: 300, maxSize: 100 };

      const cacheEntry = {
        data,
        timestamp: Date.now(),
        ttl: config.ttl,
        strategy: _strategy
      };

      if (this.dbManager.redisClient) {
        await this.dbManager.redisClient.setEx(key, config.ttl, JSON.stringify(cacheEntry));
      }

      // Also maintain in-memory cache for faster access
      this.inMemoryCache = this.inMemoryCache || new Map();
      this.inMemoryCache.set(key, cacheEntry);

      // Enforce max size
      if (this.inMemoryCache.size > config.maxSize) {
        const oldestKey = this.inMemoryCache.keys().next().value;
        this.inMemoryCache.delete(oldestKey);
      }

    } catch (error) {
      console.error('Cache set error:', error);
    }
  }

  async delete(key) {
    try {
      if (this.dbManager.redisClient) {
        await this.dbManager.redisClient.del(key);
      }
      if (this.inMemoryCache) {
        this.inMemoryCache.delete(key);
      }
    } catch (error) {
      console.error('Cache delete error:', error);
    }
  }

  isExpired(cacheEntry) {
    return Date.now() - cacheEntry.timestamp > (cacheEntry.ttl * 1000);
  }

  // Cache warming for frequently accessed data
  async warmCache() {
    console.log('üî• Warming database cache...');

    try {
      // Cache frequently accessed user data
      if (this.dbManager.prisma) {
        const activeUsers = await this.dbManager.prisma.user.findMany({
          where: { /* active users criteria */ },
          take: 100
        });

        for (const user of activeUsers) {
          await this.set(`user:${user.id}`, user, 'user');
        }
      }

      console.log('‚úÖ Cache warming completed');
    } catch (error) {
      console.error('Cache warming error:', error);
    }
  }
}

// ============================================================================
// REAL-TIME SYNC ENGINE
// ============================================================================

class SyncEngine {
  constructor(dbManager) {
    this.dbManager = dbManager;
    this.subscribers = new Map();
    this.syncQueues = new Map();
  }

  // Subscribe to real-time updates
  subscribe(entityType, entityId, callback) {
    const key = `${entityType}:${entityId}`;
    if (!this.subscribers.has(key)) {
      this.subscribers.set(key, new Set());
    }
    this.subscribers.get(key).add(callback);

    // Return unsubscribe function
    return () => {
      const subscribers = this.subscribers.get(key);
      if (subscribers) {
        subscribers.delete(callback);
        if (subscribers.size === 0) {
          this.subscribers.delete(key);
        }
      }
    };
  }

  // Publish updates to subscribers
  async publish(entityType, entityId, data, operation = 'update') {
    const key = `${entityType}:${entityId}`;

    // Store in Redis for pub/sub
    if (this.dbManager.redisClient) {
      await this.dbManager.redisClient.publish(key, JSON.stringify({
        operation,
        data,
        timestamp: new Date().toISOString()
      }));
    }

    // Notify local subscribers
    const subscribers = this.subscribers.get(key);
    if (subscribers) {
      subscribers.forEach(callback => {
        try {
          callback(data, operation);
        } catch (error) {
          console.error('Subscriber callback error:', error);
        }
      });
    }

    // Queue for cross-service sync
    this.queueForSync(entityType, entityId, data, operation);
  }

  queueForSync(entityType, entityId, data, operation) {
    const queueKey = `sync:${entityType}`;
    if (!this.syncQueues.has(queueKey)) {
      this.syncQueues.set(queueKey, []);
    }

    this.syncQueues.get(queueKey).push({
      entityId,
      data,
      operation,
      timestamp: new Date().toISOString(),
      retryCount: 0
    });

    // Process queue
    this.processSyncQueue(queueKey);
  }

  async processSyncQueue(queueKey) {
    const queue = this.syncQueues.get(queueKey);
    if (!queue || queue.length === 0) return;

    const item = queue.shift();

    try {
      await this.syncToExternalServices(queueKey.replace('sync:', ''), item);
    } catch (error) {
      console.error('Sync error:', error);
      item.retryCount++;

      if (item.retryCount < 3) {
        // Retry with exponential backoff
        setTimeout(() => {
          queue.unshift(item);
          this.processSyncQueue(queueKey);
        }, Math.pow(2, item.retryCount) * 1000);
      }
    }
  }

  async syncToExternalServices(entityType, item) {
    // Sync to external services like AI orchestrator, analytics, etc.
    const syncTargets = {
      'user': ['ai-orchestrator', 'analytics'],
      'job': ['ai-orchestrator', 'quantum-tracking'],
      'trip': ['analytics', 'quantum-tracking'],
      'incident': ['ai-orchestrator', 'compliance']
    };

    const targets = syncTargets[entityType] || [];
    const results = [];

    for (const target of targets) {
      try {
        const result = await this.syncToService(target, entityType, item);
        results.push({ target, success: true, result });
      } catch (error) {
        results.push({ target, success: false, error: error.message });
      }
    }

    return results;
  }

  async syncToService(serviceName, entityType, item) {
    // This would make HTTP calls to other services
    // For now, just log the sync attempt
    console.log(`üîÑ Syncing ${entityType} to ${serviceName}:`, item.entityId);

    // In production, this would be:
    // const response = await fetch(`${serviceUrls[serviceName]}/sync/${entityType}`, {
    //   method: 'POST',
    //   headers: { 'Content-Type': 'application/json' },
    //   body: JSON.stringify(item)
    // });

    return { synced: true, timestamp: new Date().toISOString() };
  }
}

// ============================================================================
// INITIALIZE SERVICES
// ============================================================================

const dbManager = new DatabaseManager();
const analytics = new AnalyticsEngine(dbManager);
const cache = new CacheEngine(dbManager);
const sync = new SyncEngine(dbManager);

// ============================================================================
// MIDDLEWARE
// ============================================================================

app.use(cors());
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Request logging
app.use((req, res, next) => {
  console.log(`${new Date().toISOString()} - ${req.method} ${req.path}`);
  next();
});

// ============================================================================
// HEALTH & MONITORING ENDPOINTS
// ============================================================================

// Health check
app.get('/health', async (req, res) => {
  const status = dbManager.getConnectionStatus();

  res.json({
    service: 'Database & Analytics Integration',
    status: status.overall ? 'healthy' : 'degraded',
    databases: status,
    timestamp: new Date().toISOString(),
    version: '1.0.0'
  });
});

// Detailed health check
app.get('/health/detailed', async (req, res) => {
  const status = dbManager.getConnectionStatus();

  let dbStats = {};
  try {
    if (status.postgresql && dbManager.prisma) {
      const userCount = await dbManager.prisma.user.count();
      const jobCount = await dbManager.prisma.job.count();
      dbStats.postgresql = { users: userCount, jobs: jobCount };
    }

    if (status.mongodb && dbManager.mongoDb) {
      const collections = await dbManager.mongoDb.collections();
      dbStats.mongodb = {
        collections: collections.length,
        collectionsList: collections.map(c => c.collectionName)
      };
    }

    if (status.redis && dbManager.redisClient) {
      const info = await dbManager.redisClient.info();
      const dbSize = info.split('\n').find(line => line.startsWith('db0:keys='))?.split('=')[1] || '0';
      dbStats.redis = { keys: parseInt(dbSize) };
    }
  } catch (error) {
    dbStats.error = error.message;
  }

  res.json({
    service: 'Database & Analytics Integration',
    status: status.overall ? 'healthy' : 'degraded',
    databases: status,
    stats: dbStats,
    cache: {
      inMemorySize: cache.inMemoryCache?.size || 0
    },
    timestamp: new Date().toISOString()
  });
});

// ============================================================================
// ANALYTICS ENDPOINTS
// ============================================================================

// Get company metrics
app.get('/analytics/metrics/:companyId', async (req, res) => {
  try {
    const { companyId } = req.params;
    const { timeframe = '30d' } = req.query;

    const cacheKey = `metrics:${companyId}:${timeframe}`;
    let metrics = await cache.get(cacheKey, 'metrics');

    if (!metrics) {
      metrics = await analytics.calculateMetrics(companyId, timeframe);
      await cache.set(cacheKey, metrics, 'metrics');
    }

    res.json({ success: true, metrics });
  } catch (error) {
    console.error('Metrics error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// Get predictions
app.get('/analytics/predictions/:companyId/:metricType', async (req, res) => {
  try {
    const { companyId, metricType } = req.params;

    const predictions = await analytics.generatePredictions(companyId, metricType);

    res.json({ success: true, predictions });
  } catch (error) {
    console.error('Predictions error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// Get analytics dashboard data
app.get('/analytics/dashboard/:companyId', async (req, res) => {
  try {
    const { companyId } = req.params;
    const { timeframe = '30d' } = req.query;

    // Get multiple metrics in parallel
    const [metrics, revenuePredictions, safetyPredictions] = await Promise.all([
      analytics.calculateMetrics(companyId, timeframe),
      analytics.generatePredictions(companyId, 'financial.totalRevenue'),
      analytics.generatePredictions(companyId, 'safety.totalIncidents')
    ]);

    // Get recent AI insights
    let insights = [];
    if (dbManager.prisma) {
      insights = await dbManager.prisma.aIInsight.findMany({
        where: { companyId },
        orderBy: { createdAt: 'desc' },
        take: 5
      });
    }

    res.json({
      success: true,
      dashboard: {
        metrics,
        predictions: {
          revenue: revenuePredictions,
          safety: safetyPredictions
        },
        insights,
        generatedAt: new Date().toISOString()
      }
    });
  } catch (error) {
    console.error('Dashboard error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ============================================================================
// DATA MANAGEMENT ENDPOINTS
// ============================================================================

// PostgreSQL query endpoint (admin only)
app.post('/data/postgresql/query', async (req, res) => {
  try {
    const { query, params = [] } = req.body;

    // Basic security check - only allow SELECT queries for now
    if (!query.trim().toUpperCase().startsWith('SELECT')) {
      return res.status(403).json({ error: 'Only SELECT queries allowed' });
    }

    if (!dbManager.prisma) {
      return res.status(503).json({ error: 'PostgreSQL not connected' });
    }

    const result = await dbManager.prisma.$queryRawUnsafe(query, ...params);

    res.json({ success: true, data: result });
  } catch (error) {
    console.error('PostgreSQL query error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// MongoDB collection operations
app.get('/data/mongodb/:collection', async (req, res) => {
  try {
    const { collection } = req.params;
    const { limit = 100, skip = 0, filter = '{}' } = req.query;

    if (!dbManager.mongoDb) {
      return res.status(503).json({ error: 'MongoDB not connected' });
    }

    const mongoCollection = dbManager.mongoDb.collection(collection);
    const query = JSON.parse(filter);

    const documents = await mongoCollection
      .find(query)
      .limit(parseInt(limit))
      .skip(parseInt(skip))
      .toArray();

    const total = await mongoCollection.countDocuments(query);

    res.json({
      success: true,
      data: documents,
      pagination: { total, limit: parseInt(limit), skip: parseInt(skip) }
    });
  } catch (error) {
    console.error('MongoDB query error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// Redis cache operations
app.get('/data/redis/:key', async (req, res) => {
  try {
    const { key } = req.params;

    if (!dbManager.redisClient) {
      return res.status(503).json({ error: 'Redis not connected' });
    }

    const value = await dbManager.redisClient.get(key);

    res.json({
      success: true,
      key,
      value: value ? JSON.parse(value) : null,
      exists: value !== null
    });
  } catch (error) {
    console.error('Redis get error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ============================================================================
// REAL-TIME SYNC ENDPOINTS
// ============================================================================

// Subscribe to entity updates
app.post('/sync/subscribe/:entityType/:entityId', async (req, res) => {
  try {
    const { entityType, entityId } = req.params;
    const { webhookUrl } = req.body;

    // In production, this would register webhooks
    // For now, just acknowledge
    console.log(`üì° Subscribed to ${entityType}:${entityId} updates`);

    res.json({
      success: true,
      subscription: { entityType, entityId, webhookUrl },
      message: 'Subscription registered'
    });
  } catch (error) {
    console.error('Subscription error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// Publish entity update
app.post('/sync/publish/:entityType/:entityId', async (req, res) => {
  try {
    const { entityType, entityId } = req.params;
    const { data, operation = 'update' } = req.body;

    await sync.publish(entityType, entityId, data, operation);

    res.json({
      success: true,
      published: { entityType, entityId, operation },
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Publish error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ============================================================================
// CACHE MANAGEMENT ENDPOINTS
// ============================================================================

// Get cache statistics
app.get('/cache/stats', async (req, res) => {
  try {
    let redisStats = {};
    if (dbManager.redisClient) {
      const info = await dbManager.redisClient.info();
      redisStats = {
        connected_clients: info.split('\n').find(line => line.startsWith('connected_clients:'))?.split(':')[1],
        used_memory: info.split('\n').find(line => line.startsWith('used_memory:'))?.split(':')[1],
        total_keys: info.split('\n').find(line => line.startsWith('db0:keys='))?.split('=')[1]
      };
    }

    res.json({
      success: true,
      cache: {
        inMemory: {
          size: cache.inMemoryCache?.size || 0,
          strategies: Object.keys(cache.cacheStrategies)
        },
        redis: redisStats
      }
    });
  } catch (error) {
    console.error('Cache stats error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// Clear cache
app.post('/cache/clear', async (req, res) => {
  try {
    const { pattern = '*' } = req.body;

    if (dbManager.redisClient) {
      const keys = await dbManager.redisClient.keys(pattern);
      if (keys.length > 0) {
        await dbManager.redisClient.del(keys);
      }
    }

    // Clear in-memory cache
    if (cache.inMemoryCache) {
      cache.inMemoryCache.clear();
    }

    res.json({
      success: true,
      cleared: true,
      pattern,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    console.error('Cache clear error:', error);
    res.status(500).json({ success: false, error: error.message });
  }
});

// ============================================================================
// STARTUP
// ============================================================================

async function startServer() {
  try {
    // Connect to all databases (won't fail if not configured)
    await dbManager.connectAll();

    // Warm up cache (only if Redis is available)
    if (dbManager.connections.redis) {
      await cache.warmCache();
    }

    // Start the server regardless of database connections
    app.listen(PORT, () => {
      console.log(`üóÑÔ∏è  Database & Analytics Integration Service online on port ${PORT}`);
      console.log(`üìä PostgreSQL: ${dbManager.connections.postgresql ? '‚úÖ' : '‚ùå'} Connected`);
      console.log(`üçÉ MongoDB: ${dbManager.connections.mongodb ? '‚úÖ' : '‚ùå'} Connected`);
      console.log(`üî¥ Redis: ${dbManager.connections.redis ? '‚úÖ' : '‚ùå'} Connected`);
      console.log(`üìà Analytics Engine: ‚úÖ Active`);
      console.log(`üíæ Intelligent Caching: ${dbManager.connections.redis ? '‚úÖ' : '‚ö†Ô∏è'} Active (Redis required)`);
      console.log(`üîÑ Real-time Sync: ${dbManager.connections.redis ? '‚úÖ' : '‚ö†Ô∏è'} Active (Redis required)`);
      console.log(`üöÄ Ready to power Azora OS data operations`);
    });

  } catch (error) {
    console.error('Failed to start database service:', error);
    process.exit(1);
  }
}

// Graceful shutdown
process.on('SIGTERM', async () => {
  console.log('üõë Shutting down database service...');
  await dbManager.disconnectAll();
  process.exit(0);
});

process.on('SIGINT', async () => {
  console.log('üõë Shutting down database service...');
  await dbManager.disconnectAll();
  process.exit(0);
});

startServer();

export {
  dbManager,
  analytics,
  cache,
  sync,
  DB_CONFIG
};
export default app;